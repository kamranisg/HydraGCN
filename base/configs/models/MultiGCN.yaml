# Blueprint
MultiGCN:
    num: 5  # Number of Dynamic and Aggregator Block pairs

    # -----------------------------------------
    # First block will learn feature representations using GCN
    DynamicBlock0:
        distributor:
            # Dummy multi-feature input
            - 0
            - 0
        ParallelGNN:
            Model0:
                model: PyGCN
                order:
                    - 0
                    - 1
                layers: 2
                activation:
                    name: ReLU

                layer0:
                    in_channels:
                    out_channels: 128

                layer1:
                    in_channels: 128
                    out_channels: 64

    AggregatorBlock0:
        distributor:
            -
                - 0
            -
                - 1

        ParallelAgg:
            Agg0:
                agg: Pass
                order:
                    - 0
                    - 1
    # -----------------------------------------
    # Second block linear layer
    DynamicBlock1:
        distributor:
            - 0
            - 1
        ParallelMLP:
            Model0:
                model: PyMLP
                order:
                    - 0
                    - 1
                activation:
                    name: ReLU
                layers: 1
                layer0:
                    in_features: 64
                    out_features: 10

    AggregatorBlock1:
        distributor:
            -
                - 0
                - 1
        ParallelAgg:
            Agg0:
                agg: Stack
                dim: 1
                order:
                    - 0

    # -----------------------------------------
    # Third block learns patient specific self-attention using LSTMs.
    DynamicBlock2:
        distributor:
            - 0
            - 0

        ParallelRNN:
            Model0:
                model: PyLSTM
                order:
                    - 0
                layers: 1
                layer0:
                    input_size: 10
                    hidden_size: 10

                fc_layer:
                    in_features: 10
                    out_features: 2

                activation:
                    name: Softmax

        ParallelMLP:
            Model0:
                model: PyPass
                order:
                    - 1
                layers: 1
                layer0:
                    input_size: 32
                    hidden_size: 32

    AggregatorBlock2:
        distributor:
            -
                - 0
            -
                - 1
        ParallelAgg:
            Agg0:
                agg: Stack
                dim: -1
                order:
                    - 0
            Agg1:
                agg: Pass
                order:
                    - 1

    # -----------------------------------------
    # Fourth block
    DynamicBlock3:
        distributor:
            - 0
            - 1

        ParallelMLP:
            Model0:
                model: PyPass
                order:
                    - 0
                    - 1
                layers: 1
                layer0:
                    input_size:
                    hidden_size:
                        - 1
                        - 10


    AggregatorBlock3:
        distributor:
            -
                - 0
                - 1
        ParallelAgg:
            Agg0:
                agg: Multiply
                order:
                    - 0

# -----------------------------------------
# Fifth block
    DynamicBlock4:
        distributor:
            - 0

        ParallelMLP:
            Model0:
                model: PyPass
                order:
                    - 0
                layers: 1
                layer0:
                    input_size:
                    hidden_size:

    AggregatorBlock4:
        distributor:
            -
                - 0
        ParallelAgg:
            Agg0:
                agg: Average
                dim: 1
                order:
                    - 0